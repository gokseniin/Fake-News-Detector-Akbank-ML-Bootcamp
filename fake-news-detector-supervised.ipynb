{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11604520,"sourceType":"datasetVersion","datasetId":7278464}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Kütüphanelerin Yüklenmesi\n\nProjemizde kullanacağımız temel Python kütüphanelerini yüklüyoruz.\n#### Numpy\nNumPy bilimsel hesaplamaların hızlı bir şekilde yapılabilmesini sağlayan bir matematik kütüphanesidir. Çok boyutlu dizileri ve matrisleri destekler.\n#### Pandas\nVeri işleme ve analizi için sıklıkla kullanılan bir kütüphanedir. Verinin tablo yapısında işlenmesine olanak tanır.\n\n#### Matplotlib\nVeri görselleştirme için kullanılan temel Python kütüphanesidir, grafik oluşturmayı ve bu grafikler üzerinde farklı görselleştirmeler yapmayı sağlar.\n\n#### Seaborn\nMatplotlib tabanlı istatistiksel bir veri görselleştirme kütüphanesidir. Estetik ve anlamlı grafikler elde etmeyi sağlar.\n\nAyrıca kod sayfamızın temiz gözükmesi için uyarıları gizledik.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:55:05.774187Z","iopub.execute_input":"2025-05-25T18:55:05.774485Z","iopub.status.idle":"2025-05-25T18:55:10.222643Z","shell.execute_reply.started":"2025-05-25T18:55:05.774464Z","shell.execute_reply":"2025-05-25T18:55:10.221594Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Veri Setinin Yüklenmesi\n\nVeri setimizi Kaggle ortamına dahil ediyoruz. Veri seti iki ayrı dosya halinde verilmiştir: \"Fake.csv\" ve \"True.csv\".  \nBu dosyaları okuyup, her birine **\"label\"** sütunu ekleyerek tek bir veri çerçevesi haline getiriyoruz. Verileri, tablo yapısında elde edebilmek için; **\"pd\"** (Pandas) kütüphanesini kullanarak **\"df\"** isimli DataFrame'e atadık.\n","metadata":{}},{"cell_type":"code","source":"fake = pd.read_csv(\"/kaggle/input/real-and-fake-news/Fake.csv\")\nreal = pd.read_csv(\"/kaggle/input/real-and-fake-news/True.csv\")\n\nfake['label'] = 1  #fake haberler = 1\nreal['label'] = 0  #gerçek haberler = 0\n\ndf = pd.concat([fake, real], ignore_index=True) #birleştirme işlemi\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:55:10.223723Z","iopub.execute_input":"2025-05-25T18:55:10.224206Z","iopub.status.idle":"2025-05-25T18:55:13.434621Z","shell.execute_reply.started":"2025-05-25T18:55:10.224174Z","shell.execute_reply":"2025-05-25T18:55:13.433697Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Veri Setinin Karıştırılması (Shuffle)\n\nFake ve Real haberler iki farklı dosyada tutulduğu için, veri seti birleştirildiğinde sıralı (önce tüm fake haberler, sonra tüm real haberler) hale gelmiştir.  \nBu durum, eğitim ve test ayrımında modelin tüm etiketleri tek sınıftan öğrenmesine neden olabilir. **\"sample()\"** metodunu kullanarak veri setini karıştırıyoruz.","metadata":{}},{"cell_type":"code","source":"df = df.sample(frac=1, random_state=42).reset_index(drop=True) #veri setini karıştır\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:55:13.436674Z","iopub.execute_input":"2025-05-25T18:55:13.436960Z","iopub.status.idle":"2025-05-25T18:55:13.469153Z","shell.execute_reply.started":"2025-05-25T18:55:13.436936Z","shell.execute_reply":"2025-05-25T18:55:13.468286Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Veri Setinin Genel Yapısı\nVeri setinin yapısını anlamak için **\"info()\"** metodunu kullanıyoruz. Veri setimiz 44898 satır ve 5 sütundan oluşuyor. Bu kümedeki 4 değişkeni tahminleyici olarak, 1 değişkeni ise hedef değişken olarak kullanacağız. Hedef değişken olarak \"label\" sütununu seçiyoruz çünkü haberlerin gerçek mi fake mi olduğu bilgisi bu sütunda bulunuyor.\n\nKütüphanelerimizin doğru şekilde çalışabilmesi için verinin tamamının non-null ve aynı veri tipinde olması gerekmektedir, bunu kontrol edelim:\n\n\"Dtype\" bilgisinde görüldüğü üzere tüm veriler aynı veri tipinde. **\"isnull()\"** ile null veri olmadığını teyit ediyoruz.","metadata":{}},{"cell_type":"code","source":"df.info()\nprint(\"\\nSatır sayısı:\", df.shape[0])\nprint(\"Sütun sayısı:\", df.shape[1])\ndf.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:55:13.470163Z","iopub.execute_input":"2025-05-25T18:55:13.470509Z","iopub.status.idle":"2025-05-25T18:55:13.535329Z","shell.execute_reply.started":"2025-05-25T18:55:13.470478Z","shell.execute_reply":"2025-05-25T18:55:13.534199Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Etiket (label) Sütununun Dağılımı\n\nHedef değişkenimiz olan \"**label**\" sütunundaki, fake/real haberlerin sayısını matplotlib kütüphanesi aracılığıyla grafik görünümünde inceliyoruz:\n\n23481 adet fake, 21417 adet real haber olduğunu gözlemledik; oran farkı çok fazla değil yani dağılım dengeli. Dağılımın dengeli olması modelin taraflı olma riskini azaltır. ","metadata":{}},{"cell_type":"code","source":"sns.countplot(data=df, x='label')\nplt.title(\"Etiket Dağılımı (Gerçek vs Sahte Haber)\")\nplt.xlabel(\"Label (0 = Real, 1 = Fake)\")\nplt.ylabel(\"Adet\")\nplt.show()\n\ndf['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:55:13.536431Z","iopub.execute_input":"2025-05-25T18:55:13.537058Z","iopub.status.idle":"2025-05-25T18:55:13.784009Z","shell.execute_reply.started":"2025-05-25T18:55:13.537019Z","shell.execute_reply":"2025-05-25T18:55:13.782933Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Veriyi Anlama (Haber Kategorilerinin Dağılımı)\n\nVeri setindeki haberlerin hangi kategorilere ait olduğunu analiz ediyoruz. Veri setinde haber konuları çeşitlilik gösteriyor, **\"subject\"** sütunu modeli beslemek için anlamlı olabilir. Bazı konular sahte habere daha yatkın olabilir bu nedenle bu sütunu sayısallaştırarak modele dahil etmek mantıklı olacaktır.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.countplot(data=df, x='subject', order=df['subject'].value_counts().index)\nplt.xticks(rotation=45)\nplt.title(\"Haber Konularının Dağılımı\")\nplt.xlabel(\"Konu\")\nplt.ylabel(\"Haber Sayısı\")\nplt.show()\n\ndf['subject'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:55:13.785027Z","iopub.execute_input":"2025-05-25T18:55:13.785428Z","iopub.status.idle":"2025-05-25T18:55:14.111759Z","shell.execute_reply.started":"2025-05-25T18:55:13.785398Z","shell.execute_reply":"2025-05-25T18:55:14.110801Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Metin Uzunluklarının Dağılımı\n\nHaber metinlerinin uzunluklarını inceleyerek fake/real haberler arasında fark olup olmadığına bakıyoruz:\n\nOrtalama uzunluk: 2.469 karakter                           \nMaksimum: 51.794 karakter (aşırı uzun bir haber)                    \nMinimum: 1 karakter (muhtemelen boş ya da anlamsız içerik — bunu filtrelememiz gerekebilir)              \nDağılım sağa çarpık (çoğu haber kısa, bazıları aşırı uzun)","metadata":{}},{"cell_type":"code","source":"df['text_length'] = df['text'].apply(len)\n\nplt.figure(figsize=(10,5))\nsns.histplot(data=df, x='text_length', hue='label', bins=50, kde=True)\nplt.title('Haber Metni Uzunluğu Dağılımı (Label Bazlı)')\nplt.xlabel('Metin Uzunluğu (Karakter)')\nplt.ylabel('Haber Sayısı')\nplt.show()\n\ndf['text_length'].describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:55:14.112790Z","iopub.execute_input":"2025-05-25T18:55:14.113107Z","iopub.status.idle":"2025-05-25T18:55:14.867415Z","shell.execute_reply.started":"2025-05-25T18:55:14.113079Z","shell.execute_reply":"2025-05-25T18:55:14.866150Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Veri Ön İşleme: Gürültülü Verilerin Temizlenmesi\n\nBir önceki adımda (\"text_length\" özelliği ile) gerçekleştirdiğimiz analizde, bazı haberlerin sadece 1 karakter uzunluğunda olduğunu gözlemlemiştik. \nBu tarz veriler model için anlamsız ve yanıltıcı olabileceğinden, bu haberleri veri setinden çıkarıyoruz.","metadata":{}},{"cell_type":"code","source":"df = df[df['text'].apply(len) > 10]  #10 karakterden kısa olan haberleri temizliyoruz\ndf.reset_index(drop=True, inplace=True)\nprint(\"Yeni veri seti boyutu:\", df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:55:14.868645Z","iopub.execute_input":"2025-05-25T18:55:14.868986Z","iopub.status.idle":"2025-05-25T18:55:14.904420Z","shell.execute_reply.started":"2025-05-25T18:55:14.868961Z","shell.execute_reply":"2025-05-25T18:55:14.903523Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9. Kategorik Verilerin Sayısallaştırılması (One-Hot Encoding)\n\nMakine öğrenmesi algoritmaları kategorik (yazı tipi) verilerle doğrudan çalışamaz. Bu nedenle \"**subject**\" sütununu modelin anlayabileceği şekilde One-Hot Encoding yöntemiyle sayısal formata dönüştürüyoruz.\nBu işlemi \"get_dummies()\" metodu aracılığıyla gerçekleştiriyoruz. Bu metot her bir kategorik değeri ayrı bir sütun haline getirip 0 ve 1'lerle temsil etmeyi sağlar.\n\nAyrıca \"drop_first=True\" kullanarak kategorinin ilk değerini atıyoruz, böylece veri setinde gereksiz fazlalık oluşmasını önlemiş oluyoruz.","metadata":{}},{"cell_type":"code","source":"df = pd.get_dummies(df, columns=['subject'], drop_first=True)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:55:14.907937Z","iopub.execute_input":"2025-05-25T18:55:14.908201Z","iopub.status.idle":"2025-05-25T18:55:14.943566Z","shell.execute_reply.started":"2025-05-25T18:55:14.908181Z","shell.execute_reply":"2025-05-25T18:55:14.942574Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10. Haber Metinlerinin Sayısallaştırılması (TF-IDF)\nVeri setimizdeki **\"text\"** ve **\"title\"** sütunları, haberlerin metinsel içeriğini içermektedir. Makine öğrenmesi algoritmaları metinleri doğrudan anlayamadığından metinleri sayısal verilere çevirmemiz gerekir. Bu işlem için yeni bir kütüphane kullanacağız.\n\n#### Scikit-learn (sklearn):\nMakine öğrenmesi modelleri, veri ön işleme (TF-IDF, encoding), veri bölme (train_test_split) ve model değerlendirme işlemleri için kullanılır. **\"TfidfVectorizer (from sklearn)\"** metin verilerini sayısal vektörlere dönüştürmek için kullanılan özel bir sınıftır.\n\n### TF-IDF Nedir?\nTF-IDF (Term Frequency - Inverse Document Frequency), bir kelimenin bir belge içerisindeki önemini ölçen bir tekniktir.\n\n#### TF (Term Frequency): \nKelimenin ilgili belge içinde kaç kez geçtiği.          \n#### IDF (Inverse Document Frequency):\nKelimenin tüm belgelerdeki yaygınlığına göre ağırlık düşürme.\n\nBu yöntem sayesinde anlamsız veya çok sık geçen kelimeler (örn: \"ve\", \"bu\", \"bir\") daha az etkili olur, önemli kelimeler öne çıkar.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n#text için TF-IDF\ntfidf_text = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', max_features=5000)\nX_text = tfidf_text.fit_transform(df['text'])\n\n#title için TF-IDF\ntfidf_title = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', max_features=1000)\nX_title = tfidf_title.fit_transform(df['title'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:55:14.944413Z","iopub.execute_input":"2025-05-25T18:55:14.944671Z","iopub.status.idle":"2025-05-25T18:56:07.684665Z","shell.execute_reply.started":"2025-05-25T18:55:14.944649Z","shell.execute_reply":"2025-05-25T18:56:07.683729Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11. Özellik Seçimi ve Hazırlık\n\nVeri setindeki *\"date\"* sütunu ile model genelleme yapmakta zorlanabilir bu nedenle modelde kullanmayacağız.  \n*\"text_length\"* sütununun sınıflar arasında yeterince ayırt edici olmadığını düşündüğümüz için kullanmaktan vazgeçtik.\n\nModelde kullanılacak ana özellikler:\n- **\"text\"** (TF-IDF, max_features=5000)\n- **\"title\"** (TF-IDF, max_features=1000)\n- **\"subject\"** (Bu sütunu ekleyip eklemeyeceğimize deneyip sonuçlara bakarak karar vereceğiz.)\n","metadata":{}},{"cell_type":"code","source":"df = df.drop(['date', 'text_length'], axis=1) #gereksiz sütunları kaldırdık","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:56:07.685798Z","iopub.execute_input":"2025-05-25T18:56:07.686154Z","iopub.status.idle":"2025-05-25T18:56:07.697673Z","shell.execute_reply.started":"2025-05-25T18:56:07.686127Z","shell.execute_reply":"2025-05-25T18:56:07.696760Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12.1. Özellik Birleştirme – Versiyon 1 (Subject Sütunu Dahil Değil)\n\nBu versiyonda modele yalnızca haberin metni (text) ve başlığı (title) TF-IDF yöntemiyle dönüştürülerek dahil ettik.\n\"subject\" sütunu, modelin performansına etkisi ayrıca test edileceği için bu versiyonda bilinçli olarak dışarıda bıraktık.\n\nTF-IDF işlemi sonucu oluşan X_text ve X_title matrisleri; normal pandas DataFrame değil, sparse matrix (seyrek matris) formatındadır. Bu format, büyük boyutlu metin verisini daha verimli saklamak için kullanılır.\n**\"hstack()\"** metodu aracılığıyla yatay (horizontal) olarak iki sparse matrisi yan yana ekledik.","metadata":{}},{"cell_type":"code","source":"from scipy.sparse import hstack\n\n#subject hariç: sadece metin ve başlık\nX = hstack([X_text, X_title]) #iki matrisi birleştirdik (giriş verisi)\ny = df['label'] #modelin tahmin etmeye çalışacağı hedef değişken (iki versiyon için de aynı)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:56:07.698935Z","iopub.execute_input":"2025-05-25T18:56:07.699459Z","iopub.status.idle":"2025-05-25T18:56:07.819347Z","shell.execute_reply.started":"2025-05-25T18:56:07.699432Z","shell.execute_reply":"2025-05-25T18:56:07.818349Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12.2 Özellik Birleştirme – Versiyon 2 (Subject Sütunu Dahil)\n\nBu versiyonda modele hem \"text\" ve \"title\" (TF-IDF ile), hem de \"subject\" sütununu (one-hot encoding sonrası) dahil ettik.         \nAmaç: Haberlerin konularının (subject) sınıflandırma başarısına katkısı olup olmadığını test etmek.\n\n\"subject\" sütunu, one-hot encoding işleminden sonra çok sayıda 0 ve 1 değerinden oluşan yeni sütunlara ayrılmıştır. Ancak TF-IDF ile dönüştürülmüş \"text\" ve \"title\" sütunları, genellikle küçük değerler (örneğin 0.003 gibi) içerir.     \nBu fark, modelin bazı sütunları fazla önemsemesine neden olabilir. Bu nedenle \"subject\" ile ilgili sütunları, modelin diğer girişleriyle *aynı ölçekte* olması için ölçeklendirdik. \n\nBurada **\"StandardScaler\"** sınıfı kullanılarak bu sütunlar standart sapmalarına göre normalize ettik. *\"with_mean=False\"* parametresi ile sparse matris yapısına uygun hale getiriyoruz.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom scipy.sparse import csr_matrix\n\n#subject dışındaki sayısallaştırılmış sütunları aldık\nsubject_cols = df.drop(['text', 'title', 'label'], axis=1).values\n\nscaler = StandardScaler(with_mean=False)\nsubject_scaled = scaler.fit_transform(subject_cols) #ölçekle\n\nX_with_subject = hstack([X_text, X_title, csr_matrix(subject_scaled)]) #birleştir\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:56:07.820348Z","iopub.execute_input":"2025-05-25T18:56:07.820643Z","iopub.status.idle":"2025-05-25T18:56:07.922632Z","shell.execute_reply.started":"2025-05-25T18:56:07.820614Z","shell.execute_reply":"2025-05-25T18:56:07.921844Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 13. Eğitim ve Test Verisinin Ayrılması\n\nModel eğitimi için, özellikler (*X*) ve hedef değişken (*y*) eğitim ve test setlerine ayırıyoruz.\nVerinin %80’ini eğitim, %20’sini test için kullanacağız.\n\nBu işlemi iki ayrı özellik kümesi için de yapacağız:\n- Versiyon 1: `text + title` özellikleri\n- Versiyon 2: `text + title + subject` özellikleri","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#versiyon 1 (subject HARİÇ)\nX_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y, test_size=0.2, random_state=42)\n\n#versiyon 2 (subject DAHİL)\nX_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_with_subject, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:56:07.923598Z","iopub.execute_input":"2025-05-25T18:56:07.923930Z","iopub.status.idle":"2025-05-25T18:56:08.113312Z","shell.execute_reply.started":"2025-05-25T18:56:07.923898Z","shell.execute_reply":"2025-05-25T18:56:08.112255Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 14. Logistic Regression ile Model Eğitimi ve Karşılaştırma\n\nİlk model olarak Logistic Regression seçtik. Bu model, metin sınıflandırma problemlerinde hızlı ve etkili sonuç vermesiyle bilinir.\nModeli, iki farklı veri seti üzerinde ayrı ayrı eğitiyoruz:\n- Versiyon 1: `text + title` (TF-IDF özellikleri)\n- Versiyon 2: `text + title + subject` (TF-IDF + kategorik veri)\n\nModellerin başarıları, doğruluk (accuracy), kesinlik (precision), duyarlılık (recall) ve F1 skoru gibi metriklerle karşılaştıracağız:       \n**Accuracy (Doğruluk):** Modelin ne kadar doğru tahmin yaptığını gösterir. Ne kadar yüksekse o kadar doğru tahmin yaptığını gösterir ancak her zaman güvenilir değildir. Sınıflar (fake/real) dengesizse yanıltıcı olabilir, sınıfların sayısı birbirine olabildiğince yakın olmalıdır.     \n**Precision (Kesinlik):** Modelin ‘sahte haber’ dediği şeylerin gerçekten ne kadar sahte olduğunu gösterir. Yani precision düşük ise, real olan haberleri fake sanma durumu çok fazladır. Bu da haksız suçlamalara ve iftiralara neden olabilir. Precision mümkün olduğunca yüksek olmalıdır.    \n**Recall (Duyarlılık / Yakalama Oranı):** Gerçekten sahte olan haberlerin ne kadarını modelin yakalayabildiğini gösterir. Recall oranı, ne kadar düşük ise model o kadar fazla fake haberi gözden kaçırıyor demektir.    \n**F1 Score (Denge Skoru):** Precision ve Recall’u dengede tutan ortak bir skordur. Modelin hem yanlış alarmları düşük olsun (precision yüksek), hem de fake haberleri gözden kaçırmasın (recall yüksek) istiyorsak F1 skoru ideal göstergedir. *F1 = 2 × (Precision × Recall) / (Precision + Recall)*","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n\ndef train_and_evaluate(X_train, X_test, y_train, y_test, label):\n    print(f\"--- {label} ---\")\n    model = LogisticRegression(max_iter=300)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n    print(\"Precision:\", precision_score(y_test, y_pred))\n    print(\"Recall:\", recall_score(y_test, y_pred))\n    print(\"F1 Score:\", f1_score(y_test, y_pred))\n    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n\n#versiyon 1 (subject HARİÇ)\ntrain_and_evaluate(X_train_1, X_test_1, y_train_1, y_test_1, \"Versiyon 1 (subject HARİÇ)\")\n\n#versiyon 2 (subject DAHİL)\ntrain_and_evaluate(X_train_2, X_test_2, y_train_2, y_test_2, \"Versiyon 2 (subject DAHİL)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:56:08.114438Z","iopub.execute_input":"2025-05-25T18:56:08.114781Z","iopub.status.idle":"2025-05-25T18:56:11.061110Z","shell.execute_reply.started":"2025-05-25T18:56:08.114735Z","shell.execute_reply":"2025-05-25T18:56:11.060299Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 15. Model Değerlendirme Sonuçları ve Veri Sızıntısı Analizi\n\nLogistic Regression modeli iki farklı özellik kümesi ile eğitildi ve test edildi:\n\n### Versiyon 1 – subject HARİÇ (Yalnızca text ve title):\n\n- **Accuracy:** 99.25%\n- **Precision:** 99.33%\n- **Recall:** 99.20%\n- **F1 Score:** 99.26%\n\nBu versiyonda model, yalnızca haber metni (text) ve başlığını (title) kullanarak yüksek başarı sağlamıştır. Bu da haberlerdeki kelime örüntülerinin sahte ve gerçek haberleri ayırt etmekte oldukça etkili olduğunu göstermektedir.\n\n\n### Versiyon 2 – subject DAHİL:\n\n- **Accuracy:** 100%\n- **Precision / Recall / F1:** 100%\n\nBu sonuç ilk bakışta mükemmel görünse de, yapılan ek analiz sonucunda modelin \"subject\" sütunundan **etiketi doğrudan ezberlediği** tespit edilmiştir. Aşağıdaki analiz ile `subject` sütunundaki her değerin yalnızca tek bir sınıfı temsil ettiği görülmüştür, bu modelin tahmin yapmak yerine direkt olarak ezberlediğinin kanıtıdır.\n\nBu aşamadan sonra **Versiyon 1** üzerinden devam edeceğiz, çünkü \"subject\" sütununu kullanmak modelimizi olumsuz etkiliyor.","metadata":{}},{"cell_type":"code","source":"#orijinal dosyaları tekrar yükle\nfake = pd.read_csv(\"/kaggle/input/real-and-fake-news/Fake.csv\")\nreal = pd.read_csv(\"/kaggle/input/real-and-fake-news/True.csv\")\n\nfake['label'] = 1 #fake = 1\nreal['label'] = 0 #real = 0\n\ncombined = pd.concat([fake, real], ignore_index=True) #birleştir\n\n#subject-label ilişki tablosu\npd.crosstab(combined['subject'], combined['label'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:56:11.061780Z","iopub.execute_input":"2025-05-25T18:56:11.062049Z","iopub.status.idle":"2025-05-25T18:56:12.828124Z","shell.execute_reply.started":"2025-05-25T18:56:11.062027Z","shell.execute_reply":"2025-05-25T18:56:12.827160Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 15. Genellenebilirlik ve Ezberleme Riski (Overfitting) İncelemesi\nModelin eğitim ve test başarıları arasında çok küçük bir fark (yaklaşık %0.4) bulunuyor.\nBu, modelin eğitim verisini ezberlemek yerine anlamlı örüntüler öğrendiğini ve overfitting yapmadığını gösteriyor.         \nYani model, test verilerinde de tutarlı şekilde başarılı tahminler yapabildi. \nBu nedenle nihai modelin gerçek dünyada genellenebilirlik açısından güvenli olduğu düşünüyorum.","metadata":{}},{"cell_type":"code","source":"#eğitim ve test skorlarını karşılaştırmak için modeli yeniden eğitiyoruz\nmodel = LogisticRegression(max_iter=300)\nmodel.fit(X_train_1, y_train_1)\n\n#eğitim seti performansı\ny_train_pred = model.predict(X_train_1)\nprint(\"EĞİTİM SETİ:\")\nprint(\"Accuracy:\", accuracy_score(y_train_1, y_train_pred))\nprint(\"F1 Score:\", f1_score(y_train_1, y_train_pred))\n\n#test seti performansı\ny_test_pred = model.predict(X_test_1)\nprint(\"\\nTEST SETİ:\")\nprint(\"Accuracy:\", accuracy_score(y_test_1, y_test_pred))\nprint(\"F1 Score:\", f1_score(y_test_1, y_test_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:56:12.828936Z","iopub.execute_input":"2025-05-25T18:56:12.829161Z","iopub.status.idle":"2025-05-25T18:56:14.965633Z","shell.execute_reply.started":"2025-05-25T18:56:12.829144Z","shell.execute_reply":"2025-05-25T18:56:14.964849Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 16. Alternatif Model: Multinomial Naive Bayes\n\nLogistic Regression modeliyle elde edilen başarıyı karşılaştırmak amacıyla, metin sınıflandırmada yaygın olarak kullanılan bir diğer model olan **Multinomial Naive Bayes** uygulayacağız.\nBu model, genellikle metin sınıflandırmada hızlı ve etkili sonuç verir ancak kelime örüntülerine dair daha yüzeysel bir analiz yapar.\n\n### Naive Bayes Performansı:\nMultinomial Naive Bayes modeli, TF-IDF ile sayısallaştırılmış \"text\" ve \"title\" verileri üzerinde eğittik.\n- *Accuracy:* 94.86%\n- *Precision:* 93.96%\n- *Recall:* 96.00%\n- *F1 Score:* 94.97%\n\n### Karşılaştırma:\n- Logistic Regression modeli %99.25 doğruluk ile daha başarılı bir performans gösterdi.\n- Naive Bayes daha basit ve hızlı bir alternatif ancak **Logistic Regression** daha tutarlı sonuçlar verdi.","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nnb_model = MultinomialNB()\nnb_model.fit(X_train_1, y_train_1)\n\ny_pred_nb = nb_model.predict(X_test_1)\n\nprint(\"Naive Bayes - TEST SETİ\")\nprint(\"Accuracy:\", accuracy_score(y_test_1, y_pred_nb))\nprint(\"Precision:\", precision_score(y_test_1, y_pred_nb))\nprint(\"Recall:\", recall_score(y_test_1, y_pred_nb))\nprint(\"F1 Score:\", f1_score(y_test_1, y_pred_nb))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test_1, y_pred_nb))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:56:14.967636Z","iopub.execute_input":"2025-05-25T18:56:14.967965Z","iopub.status.idle":"2025-05-25T18:56:15.086050Z","shell.execute_reply.started":"2025-05-25T18:56:14.967941Z","shell.execute_reply":"2025-05-25T18:56:15.084952Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 17. Alternatif Model – Support Vector Machine (SVM)\n\n**Destek Vektör Makineleri (SVM)**, yüksek boyutlu veri ile çalışmada etkili bir sınıflandırma yöntemidir.  \n\nTF-IDF ile elde edilen \"text\" ve \"title\" özellikleri ile SVM modeli eğitip, test ediyoruz.\nAmaç: Logistic Regression modeli ile karşılaştırmalı bir değerlendirme yapmak.\n\nModel, Logistic Regression ile benzer şekilde çok yüksek performans gösterdi:\n\n- *Accuracy:* 99.54%\n- *Precision:* 99.51%\n- *Recall:* 99.58%\n- *F1 Score:* 99.54%\n\n### Karşılaştırma:\n\n| Model                 | Accuracy | F1 Score |\n|-----------------------|----------|----------|\n| Logistic Regression   | 99.25%   | 99.26%   |\n| SVM                   | 99.54%   | 99.54%   |\n| Naive Bayes           | 94.86%   | 94.97%   |","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\nsvm_model = LinearSVC()\nsvm_model.fit(X_train_1, y_train_1)\n\ny_pred_svm = svm_model.predict(X_test_1)\n\nprint(\"SVM - TEST SETİ\")\nprint(\"Accuracy:\", accuracy_score(y_test_1, y_pred_svm))\nprint(\"Precision:\", precision_score(y_test_1, y_pred_svm))\nprint(\"Recall:\", recall_score(y_test_1, y_pred_svm))\nprint(\"F1 Score:\", f1_score(y_test_1, y_pred_svm))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test_1, y_pred_svm))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:56:15.087062Z","iopub.execute_input":"2025-05-25T18:56:15.087378Z","iopub.status.idle":"2025-05-25T18:56:15.666832Z","shell.execute_reply.started":"2025-05-25T18:56:15.087356Z","shell.execute_reply":"2025-05-25T18:56:15.665798Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 18. SVM Modeli Overfitting Kontrolü – Eğitim/Test Performansı Karşılaştırması\n\nModelin overfitting (aşırı öğrenme) yapıp yapmadığını anlamak için eğitim ve test seti üzerindeki performansları karşılaştıracağız:\n\n| Set       | Accuracy | F1 Score |\n|-----------|----------|----------|\n| Eğitim    | 99.99%   | 99.99%   |\n| Test      | 99.54%   | 99.54%   |\n| Fark      | ~0.45%   | ~0.45%   |\n\nBu fark çok küçük olduğu için **overfitting durumu gözlemlenmemektedir**, modelin genelleme başarısı yüksektir.","metadata":{}},{"cell_type":"code","source":"y_train_pred_svm = svm_model.predict(X_train_1)\nprint(\"EĞİTİM SETİ:\")\nprint(\"Accuracy:\", accuracy_score(y_train_1, y_train_pred_svm))\nprint(\"F1 Score:\", f1_score(y_train_1, y_train_pred_svm))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T18:56:15.667938Z","iopub.execute_input":"2025-05-25T18:56:15.668276Z","iopub.status.idle":"2025-05-25T18:56:15.707649Z","shell.execute_reply.started":"2025-05-25T18:56:15.668242Z","shell.execute_reply":"2025-05-25T18:56:15.706578Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 19. Proje Sonucu ve Genel Değerlendirme\n\nBu projede, sahte ve gerçek haberleri ayırt edebilen bir makine öğrenmesi modeli geliştirilmiştir.  \nKullanılan veri seti, Kaggle üzerinde yer alan **\"Real and Fake News\"** veri setidir ve toplamda 44.000'den fazla haber içermektedir.\n\n### Uygulanan Süreç:\n- Veri temizleme ve eksik veri analizi yapıldı.\n- *\"text\"*, *\"title\"* sütunları TF-IDF ile sayısallaştırıldı.\n- *\"subject\"* sütunu başlangıçta modele dahil edilse de, **etiketle doğrudan ilişkili** olduğu (veri sızıntısı) tespit edilerek çıkarıldı.\n- Veri **\"train_test_split\"** ile eğitim ve test kümelerine ayrıldı\n\n### Kullanılan Modeller:\n1. **Logistic Regression**  \n2. **Naive Bayes**\n3. **Support Vector Machine (SVM)**\n\n### Model Performans Karşılaştırması (Test Seti):\n\n| Model               | Accuracy | F1 Score |\n|---------------------|----------|----------|\n| Logistic Regression | 99.25%   | 99.26%   |\n| SVM                 | 99.54%   | 99.54%   |\n| Naive Bayes         | 94.86%   | 94.97%   |","metadata":{}}]}